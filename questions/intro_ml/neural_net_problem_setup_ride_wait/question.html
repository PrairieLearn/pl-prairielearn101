<pl-question-panel>
    
<markdown>
You are hired by an amusement park that wants to use machine learning to forecast wait times on their 3 busiest rides. They hope to create an application that allows visitors to plan their day in the park based on projected times.

They provide you a spreadsheet of individual ride wait times per hour for the past year, with {{params.rows}} rows and the following columns:


- record index (increments on each row in the dataset)
- month (1 to 12)
- hour (0 to 23)
- weekend (0 for M, T, W, Th and 1 for Sat, Sun)
- holiday (0 for non-holiday days, 1 for holidays)
- weather (0 for bad weather, 1 for good weather - bad weather deters visitors)
- ride index (0 to 2)
- recorded wait time for the ride, in minutes.

You decide to use a fully connected neural network with a single hidden layer.

Your network will output a vector, with the predicted wait time in minutes for each ride. For example, if the output of the network is [15, 0, 40] for a given feature vector, this means that the expected wait time is 15 minutes for ride 0, 0 minutes for ride 1, and 40 minutes for ride 2.

(Note: the ride index column will not be a "feature" input to your model, since each output from the network includes a value for each ride!)


</markdown>


    
</pl-question-panel>

<br><hr>

<p>How many input units will your network have? (Not including any bias unit.) </p>


<pl-integer-input answers-name="input" correct-answer='5'></pl-integer-input>

<pl-answer-panel><br><hr><p><span class="badge badge-primary">Comment</span> The data has 5 features, so there will be 5 input units.</p></pl-answer-panel>

<br><hr>

<p> How many output units will your network have?</p>

<pl-integer-input answers-name="output" correct-answer='3'></pl-integer-input>

<pl-answer-panel><br><hr><p><span class="badge badge-primary">Comment</span> This is a regression problem with vector output. The network should have 3 output units - one for each ride - because it will predict a value for each ride.</p></pl-answer-panel>

<br><hr>

<p>How many units will you use in the hidden layer? (Not including any bias unit.) </p>

<pl-hide-in-panel answer="true">
    <pl-integer-input answers-name="hidden" correct-answer='24'></pl-integer-input>
</pl-hide-in-panel>

<pl-answer-panel><br><hr><p><span class="badge badge-primary">Comment</span> You can select the number of hidden units; it's not dictated by the problem. 
Your choice will determine how much capacity the network has for learning a complicated function.</p></pl-answer-panel>

<br><hr>

<p>What activation function will you use at the hidden units?</p>

<pl-multiple-choice answers-name="act-hidden" weight="1" fixed-order="true" hide-letter-keys="true" number-answers="5">
  <pl-answer correct="true">relu</pl-answer>
  <pl-answer correct="false">sigmoid</pl-answer>
  <pl-answer correct="false">tanh</pl-answer>
  <pl-answer correct="false">softmax</pl-answer>
  <pl-answer correct="false">linear</pl-answer>
</pl-multiple-choice>


<pl-answer-panel><br><hr><p><span class="badge badge-primary">Comment</span> Acceptable options include relu, sigmoid, or tanh. </p>
<p>The linear activation function is not a good choice for the hidden units, since then the network will not learn any non-linear function, and will be equivalent to a classical linear regression. </p>
<p>The sofmax activation is used at the output units when we want to produce a probability distribution over a set of discrete classes, but that doesn't apply here.</p></pl-answer-panel>


<br><hr>

<p>What activation function will you use at the output units?</p>

<pl-multiple-choice answers-name="act-output" weight="1" fixed-order="true" hide-letter-keys="true">
  <pl-answer correct="false">relu</pl-answer>
  <pl-answer correct="false">sigmoid</pl-answer>
  <pl-answer correct="false">tanh</pl-answer>
  <pl-answer correct="false">softmax</pl-answer>
  <pl-answer correct="true">linear</pl-answer>
</pl-multiple-choice>


<pl-answer-panel><br><hr><p><span class="badge badge-primary">Comment</span> For a regression problem, we use a linear activation at the output units.</p></pl-answer-panel>